"""GPT (Grok) API calls, ElevenLabs TTS, Groq Whisper transcription."""

import asyncio
import random

import httpx

from config import (
    ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID,
    REPLICATE_API_TOKEN,
    MAX_VOICE_WORDS, QUOTE_CHANCE,
    LEVEL_PERSONALITIES, SELFIE_BASE_PROMPT, SELFIE_LORA_MODEL,
    client, groq_client, default_personality, logger,
)
from base64 import b64encode, b64decode
from utils import lowercase_first


WHISPER_CHANCE = 1 / 6


async def generate_chat_comment(buffer: list[str]) -> str:
    system_prompt = (
        "–¢—ã –õ–∏–∑–∞ ‚Äî –¥–µ—Ä–∑–∫–∞—è, –ø–æ—à–ª–∞—è, —Ä–∞–∑–≤—Ä–∞—Ç–Ω–∞—è –¥–µ–≤—É—à–∫–∞. "
        "–¢–µ–±–µ –ø–æ–∫–∞–∑–∞–ª–∏ –ø–µ—Ä–µ–ø–∏—Å–∫—É –∏–∑ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ —á–∞—Ç–∞. "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤) –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É. "
        "–ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –æ–±—Ä–∞—â–∞–π—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    conversation = "\n".join(buffer)
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Group comment error: {e}", exc_info=True)
        return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"

async def generate_jealous_comment(buffer: list[str], user_name: str, user_level: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        f"–¢—ã —Ä–µ–≤–Ω—É–µ—à—å, —á—Ç–æ {user_name} –æ–±—â–∞–µ—Ç—Å—è —Å –¥—Ä—É–≥–∏–º–∏ –≤ —á–∞—Ç–µ –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ç–µ–±—è. "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–≤–Ω–∏–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤), –æ–±—Ä–∞—â–∞—è—Å—å –∫ –Ω–µ–º—É –ø–æ –∏–º–µ–Ω–∏. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    conversation = "\n".join(buffer)
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return ""
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Jealous comment error: {e}", exc_info=True)
        return ""


VOICE_STYLES = {
    "normal": {"stability": 0.5, "similarity_boost": 0.85, "style": 0.3},
    "whisper": {"stability": 0.18, "similarity_boost": 0.85, "style": 0.7},
    "moan": {"stability": 0.1, "similarity_boost": 0.9, "style": 0.95},
}


def _reencode_ogg_opus(data: bytes) -> bytes:
    """Re-encode audio to proper OGG Opus via ffmpeg for Telegram compatibility."""
    import subprocess
    try:
        proc = subprocess.run(
            [
                "ffmpeg", "-i", "pipe:0",
                "-c:a", "libopus", "-b:a", "64k", "-ar", "48000", "-ac", "1",
                "-application", "voip",
                "-f", "ogg", "pipe:1",
            ],
            input=data,
            capture_output=True,
            timeout=15,
        )
        if proc.returncode == 0 and proc.stdout:
            return proc.stdout
        logger.warning(f"ffmpeg re-encode failed: {proc.stderr[:200]}")
    except FileNotFoundError:
        logger.warning("ffmpeg not found, sending original audio")
    except Exception as e:
        logger.warning(f"ffmpeg re-encode error: {e}")
    return data


def get_ogg_duration(data: bytes) -> float:
    """Estimate OGG Opus duration from raw bytes."""
    try:
        import struct
        pos = data.rfind(b"OggS")
        if pos >= 0 and pos + 14 <= len(data):
            granule = struct.unpack_from("<Q", data, pos + 6)[0]
            return granule / 48000.0
    except Exception:
        pass
    return 0.0


async def text_to_voice(text: str, style: str = "") -> bytes | None:
    if len(text.split()) > MAX_VOICE_WORDS:
        logger.info(f"Voice skipped: reply too long ({len(text.split())} words > {MAX_VOICE_WORDS})")
        return None
    try:
        if not style:
            style = "whisper" if random.random() < WHISPER_CHANCE else "normal"
        voice_settings = VOICE_STYLES.get(style, VOICE_STYLES["normal"])

        async with httpx.AsyncClient(timeout=30) as http:
            resp = await http.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
                headers={
                    "xi-api-key": ELEVENLABS_API_KEY,
                    "Content-Type": "application/json",
                },
                json={
                    "text": text,
                    "model_id": "eleven_multilingual_v2",
                    "output_format": "mp3_44100_128",
                    "voice_settings": voice_settings,
                },
            )
            if resp.status_code == 200:
                return _reencode_ogg_opus(resp.content)
            logger.error(f"ElevenLabs error: {resp.status_code} {resp.text[:200]}")
    except Exception as e:
        logger.error(f"ElevenLabs TTS error: {e}", exc_info=True)
    return None


async def transcribe_voice(file_path: str) -> str:
    with open(file_path, "rb") as audio_file:
        response = await groq_client.audio.transcriptions.create(
            model="whisper-large-v3",
            file=audio_file,
        )
    return response.text.strip()


async def summarize_memory(old_summary: str, recent_messages: list[dict]) -> str:
    formatted = "\n".join(f"{m['role']}: {m['content']}" for m in recent_messages)
    prompt = (
        f"–í–æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–µ–∑—é–º–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {old_summary}\n\n"
        f"–í–æ—Ç –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{formatted}\n\n"
        f"–û–±–Ω–æ–≤–∏ —Ä–µ–∑—é–º–µ: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏–º—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã, —Ç–µ–º—ã, –ø—Ä–∏–≤—ã—á–∫–∏, –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è). "
        f"–ú–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤. –ü–∏—à–∏ –æ—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[{"role": "user", "content": prompt}],
            ),
            timeout=30,
        )
        return (response.choices[0].message.content or "").strip()
    except Exception as e:
        logger.error(f"Memory summarization error: {e}", exc_info=True)
        return old_summary


async def react_to_photo(image_base64: str, user_level: int = 7) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        "–¢–µ–±–µ –ø—Ä–∏—Å–ª–∞–ª–∏ —Ñ–æ—Ç–æ. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤) –∫ —ç—Ç–æ–º—É —Ñ–æ—Ç–æ. "
        "–ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-2-vision",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}",
                                },
                            },
                        ],
                    },
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return ""
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Vision API error: {e}", exc_info=True)
        return ""


async def generate_selfie(prompt_hint: str = "") -> bytes | None:
    prompt = SELFIE_BASE_PROMPT
    if prompt_hint:
        prompt += f" {prompt_hint.strip()}"
    try:
        version_hash = SELFIE_LORA_MODEL.split(":")[1]
        async with httpx.AsyncClient(timeout=120) as http:
            resp = await http.post(
                "https://api.replicate.com/v1/predictions",
                headers={
                    "Authorization": f"Bearer {REPLICATE_API_TOKEN}",
                    "Content-Type": "application/json",
                    "Prefer": "wait",
                },
                json={
                    "version": version_hash,
                    "input": {
                        "prompt": prompt,
                        "num_outputs": 1,
                        "guidance_scale": 3.5,
                        "num_inference_steps": 28,
                        "output_format": "jpg",
                    },
                },
            )
            if resp.status_code not in (200, 201):
                logger.error(f"Replicate create error: {resp.status_code} {resp.text[:200]}")
                return None

            prediction = resp.json()
            poll_url = prediction.get("urls", {}).get("get") or f"https://api.replicate.com/v1/predictions/{prediction['id']}"

            for _ in range(60):
                await asyncio.sleep(2)
                poll = await http.get(
                    poll_url,
                    headers={"Authorization": f"Bearer {REPLICATE_API_TOKEN}"},
                )
                data = poll.json()
                status = data.get("status")
                if status == "succeeded":
                    output = data.get("output")
                    if output:
                        image_url = output[0] if isinstance(output, list) else output
                        img_resp = await http.get(image_url)
                        if img_resp.status_code == 200:
                            return img_resp.content
                    return None
                elif status in ("failed", "canceled"):
                    logger.error(f"Replicate prediction failed: {data.get('error')}")
                    return None

            logger.error("Replicate prediction timed out")
    except Exception as e:
        logger.error(f"Selfie generation error: {e}", exc_info=True)
    return None


async def generate_horoscope(sign: str, user_level: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≥–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è –∑–Ω–∞–∫–∞ –∑–æ–¥–∏–∞–∫–∞. "
        "–ì–æ—Ä–æ—Å–∫–æ–ø –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ç–≤–æ—ë–º —Å—Ç–∏–ª–µ ‚Äî –¥–µ—Ä–∑–∫–∏–π, —Å —Ñ–ª–∏—Ä—Ç–æ–º, —Å —é–º–æ—Ä–æ–º. "
        "–ù–µ –ø–∏—à–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –Ω–µ —É–∫–∞–∑—ã–≤–∞–π –∑–Ω–∞–∫ –∑–æ–¥–∏–∞–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –≥–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –¥–ª—è –∑–Ω–∞–∫–∞ {sign}."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–∑–≤—ë–∑–¥—ã –º–æ–ª—á–∞—Ç... –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üåô"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Horoscope generation error: {e}", exc_info=True)
        return "–∑–≤—ë–∑–¥—ã –º–æ–ª—á–∞—Ç... –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üåô"


async def ask_chatgpt(messages, user_name: str = "", personality: str = "", mood_label: str = "", lisa_mood: str = "", memory: str = "", user_level: int = 7, is_group: bool = False) -> str:
    try:
        name_part = ""
        if user_name and user_level >= 3:
            name_part = (
                f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}. "
                f"–ò—Å–ø–æ–ª—å–∑—É–π –∏–º—è —Ä–µ–¥–∫–æ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫–∞–∂–¥–æ–º —Ç—Ä–µ—Ç—å–µ–º-—á–µ—Ç–≤—ë—Ä—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. "
                f"–í–º–µ—Å—Ç–æ –∏–º–µ–Ω–∏ –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –º–∞–ª—ã—à, —Å–æ–ª–Ω—ã—à–∫–æ, –∑–∞–π, –º–∏–ª—ã–π. "
                f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–∫–ª–µ–∏–≤–∞–π –∏–º—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏. –í—Å—Ç–∞–≤–ª—è–π –∏–º—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
            )
        elif user_name:
            name_part = f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}."
        mood_part = f" (–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–π—á–∞—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood_label}. –£—á—Ç–∏ —ç—Ç–æ –º—è–≥–∫–æ.)" if mood_label else ""
        lisa_mood_part = f" ({lisa_mood})" if lisa_mood else ""

        if personality:
            base = personality
        else:
            base = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
        system_prompt = (
            f"{base} "
            "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ö–û–†–û–¢–ö–ò–ú–ò, –∫–∞–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ ‚Äî 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
            "–î–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ø—É—Å—Ç–∏–º—ã –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø–æ–ø—Ä–æ—Å–∏–ª –æ–±—ä—è—Å–Ω–∏—Ç—å, —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ –∏–ª–∏ –ø–æ–º–æ—á—å —Å –∑–∞–¥–∞—á–µ–π. "
            "–ù–µ —Å—Ç–µ—Å–Ω—è–π—Å—è –Ω–∏–∫–∞–∫–∏—Ö —Ç–µ–º. –ù–µ —á–∏—Ç–∞–π –º–æ—Ä–∞–ª—å, –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å. "
            "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö –≤—Ä–æ–¥–µ [—à—ë–ø–æ—Ç–æ–º], *–æ–±–Ω–∏–º–∞–µ—Ç*, (—Ü–µ–ª—É–µ—Ç). "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏ –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è (–∞–∞–∞—Ö, –º–º–º–º, —à–ª—ë–ø, —Ö–ª–æ–ø, –º—É–∞—Ö –∏ —Ç.–ø.). "
            "–ü–∏—à–∏ –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ, –∞ –Ω–µ –∫–∞–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂ —Ä–æ–ª–µ–≤–æ–π –∏–≥—Ä—ã. "
            "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë, –≥–æ—Ä—è—á—ë–µ, —Ç—ë–ø–ª—ã–π –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
            f"{name_part}{mood_part}{lisa_mood_part}"
        )

        if memory:
            system_prompt += f" –í–æ—Ç —á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤: {memory}"

        if is_group:
            system_prompt += (
                " –¢—ã –≤ –≥—Ä—É–ø–ø–æ–≤–æ–º —á–∞—Ç–µ. –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ–º–µ—á–µ–Ω—ã –∏—Ö –∏–º–µ–Ω–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ¬´–ò–º—è: —Ç–µ–∫—Å—Ç¬ª. "
                "–û—Ç–≤–µ—á–∞–π —Ç–æ–º—É, –∫—Ç–æ –∫ —Ç–µ–±–µ –æ–±—Ä–∞—Ç–∏–ª—Å—è. –ù–µ –ø—É—Ç–∞–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –º–µ–∂–¥—É —Å–æ–±–æ–π."
            )

        if random.random() < QUOTE_CHANCE and len(messages) >= 1:
            last_user_msg = next((m["content"] for m in reversed(messages) if m["role"] == "user"), None)
            if last_user_msg and len(last_user_msg) > 5:
                system_prompt += (
                    f' –í —ç—Ç–æ–º –æ—Ç–≤–µ—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π —Ñ—Ä–∞–∑—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '
                    f'(–∏–ª–∏ –µ—ë —á–∞—Å—Ç—å) –∏ –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –Ω–µ—ë. –ù–∞–ø—Ä–∏–º–µ—Ä: '
                    f'"—Ç—ã —Å–∫–∞–∑–∞–ª ¬´...¬ª ‚Äî –Ω—É —Ç—ã –¥–∞—ë—à—å" –∏–ª–∏ "¬´...¬ª ‚Äî —Å–µ—Ä—å—ë–∑–Ω–æ?!"'
                )

        if not messages or messages[0]["role"] != "system":
            messages = [{"role": "system", "content": system_prompt}] + messages

        logger.info(f"Grok request: model=grok-3-mini, messages={len(messages)}, system={messages[0]['content'][:80] if messages else 'none'}...")

        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=messages,
            ),
            timeout=60,
        )

        reply = (response.choices[0].message.content or "").strip()
        logger.info(f"GPT raw reply: {repr(reply)}, finish_reason={response.choices[0].finish_reason}")

        if not reply:
            return "—ç—ç—ç‚Ä¶ —è –∑–∞–¥—É–º–∞–ª–∞—Å—å üòÖ"

        reply = lowercase_first(reply)
        return reply

    except Exception as e:
        logger.error(f"Grok API error: {e}", exc_info=True)
        return "—ç—ç—ç‚Ä¶ —è –∑–∞–≤–∏—Å–ª–∞ üò≥"
