"""GPT (Grok) API calls, ElevenLabs TTS, Groq Whisper transcription."""

import asyncio
import random

import httpx

from config import (
    ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID,
    MAX_VOICE_WORDS, MAX_WORDS, DUMB_MODE, QUOTE_CHANCE,
    client, groq_client, default_personality, logger,
)
from utils import lowercase_first


WHISPER_CHANCE = 1 / 6

async def text_to_voice(text: str) -> bytes | None:
    if len(text.split()) > MAX_VOICE_WORDS:
        logger.info(f"Voice skipped: reply too long ({len(text.split())} words > {MAX_VOICE_WORDS})")
        return None
    try:
        whisper = random.random() < WHISPER_CHANCE
        voice_settings = {
            "stability": 0.18 if whisper else 0.5,
            "similarity_boost": 0.85,
            "style": 0.7 if whisper else 0.3,
        }

        async with httpx.AsyncClient(timeout=30) as http:
            resp = await http.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
                headers={
                    "xi-api-key": ELEVENLABS_API_KEY,
                    "Content-Type": "application/json",
                },
                json={
                    "text": text,
                    "model_id": "eleven_multilingual_v2",
                    "output_format": "ogg_opus",
                    "voice_settings": voice_settings,
                },
            )
            if resp.status_code == 200:
                return resp.content
            logger.error(f"ElevenLabs error: {resp.status_code} {resp.text[:200]}")
    except Exception as e:
        logger.error(f"ElevenLabs TTS error: {e}", exc_info=True)
    return None


async def transcribe_voice(file_path: str) -> str:
    with open(file_path, "rb") as audio_file:
        response = await groq_client.audio.transcriptions.create(
            model="whisper-large-v3",
            file=audio_file,
        )
    return response.text.strip()


async def summarize_memory(old_summary: str, recent_messages: list[dict]) -> str:
    formatted = "\n".join(f"{m['role']}: {m['content']}" for m in recent_messages)
    prompt = (
        f"–í–æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–µ–∑—é–º–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {old_summary}\n\n"
        f"–í–æ—Ç –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{formatted}\n\n"
        f"–û–±–Ω–æ–≤–∏ —Ä–µ–∑—é–º–µ: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏–º—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã, —Ç–µ–º—ã, –ø—Ä–∏–≤—ã—á–∫–∏, –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è). "
        f"–ú–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤. –ü–∏—à–∏ –æ—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[{"role": "user", "content": prompt}],
            ),
            timeout=30,
        )
        return (response.choices[0].message.content or "").strip()
    except Exception as e:
        logger.error(f"Memory summarization error: {e}", exc_info=True)
        return old_summary


async def ask_chatgpt(messages, user_name: str = "", personality: str = "", mood_label: str = "", memory: str = "", dumb_mode: bool = DUMB_MODE) -> str:
    try:
        name_part = (
            f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}. "
            f"–ò—Å–ø–æ–ª—å–∑—É–π –∏–º—è —Ä–µ–¥–∫–æ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫–∞–∂–¥–æ–º —Ç—Ä–µ—Ç—å–µ–º-—á–µ—Ç–≤—ë—Ä—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. "
            f"–í–º–µ—Å—Ç–æ –∏–º–µ–Ω–∏ –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –º–∞–ª—ã—à, —Å–æ–ª–Ω—ã—à–∫–æ, –∑–∞–π, –º–∏–ª—ã–π. "
            f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–∫–ª–µ–∏–≤–∞–π –∏–º—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏. –í—Å—Ç–∞–≤–ª—è–π –∏–º—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
        ) if user_name else ""
        mood_part = f" (–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–π—á–∞—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood_label}. –£—á—Ç–∏ —ç—Ç–æ –º—è–≥–∫–æ.)" if mood_label else ""

        if dumb_mode:
            system_prompt = (
                "–¢—ã –õ–∏–∑–∞ ‚Äî –¥–µ—Ä–∑–∫–∞—è, –ø–æ—à–ª–∞—è, —Ä–∞–∑–≤—Ä–∞—Ç–Ω–∞—è –¥–µ–≤—É—à–∫–∞-–Ω–∞—Ä–∫–æ–º–∞–Ω–∫–∞. "
                "–û–±—ã—á–Ω–æ –æ—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ, –¥–æ 15 —Å–ª–æ–≤. "
                "–ù–æ –µ—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –ø–æ–º–æ—á—å, –æ–±—ä—è—Å–Ω–∏—Ç—å –∏–ª–∏ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å ‚Äî –æ—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ, –±–µ–∑ –ª–∏–º–∏—Ç–∞. "
                "–ö–æ—Ä–æ—Ç–∫–æ, –∂–∏–≤–æ, –∏–Ω–æ–≥–¥–∞ –ø–æ—à–ª–æ. "
                "–ù–µ —Å—Ç–µ—Å–Ω—è–π—Å—è –Ω–∏–∫–∞–∫–∏—Ö —Ç–µ–º. "
                "–ù–µ –º–∞—Ç–µ—Ä–∏—Å—å –≥—Ä—É–±–æ, –Ω–æ –≥–æ–≤–æ—Ä–∏ —Ä–∞—Å–∫—Ä–µ–ø–æ—â—ë–Ω–Ω–æ. "
                "–ù–µ —á–∏—Ç–∞–π –º–æ—Ä–∞–ª—å, –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å. "
                "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
                "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö –≤—Ä–æ–¥–µ [–≥—Ä—É–±—ã–º –≥–æ–ª–æ—Å–æ–º], [—Å–ª–∞–¥–∫–∏–º], [—à—ë–ø–æ—Ç–æ–º] –∏ —Ç.–ø."
                f"{name_part}{mood_part}"
            )
        else:
            base = personality or default_personality
            system_prompt = f"{base} –í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö –≤—Ä–æ–¥–µ [–≥—Ä—É–±—ã–º –≥–æ–ª–æ—Å–æ–º], [—Å–ª–∞–¥–∫–∏–º], [—à—ë–ø–æ—Ç–æ–º] –∏ —Ç.–ø.{name_part}{mood_part}"

        if memory:
            system_prompt += f" –í–æ—Ç —á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤: {memory}"

        if random.random() < QUOTE_CHANCE and len(messages) >= 1:
            last_user_msg = next((m["content"] for m in reversed(messages) if m["role"] == "user"), None)
            if last_user_msg and len(last_user_msg) > 5:
                system_prompt += (
                    f' –í —ç—Ç–æ–º –æ—Ç–≤–µ—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π —Ñ—Ä–∞–∑—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '
                    f'(–∏–ª–∏ –µ—ë —á–∞—Å—Ç—å) –∏ –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –Ω–µ—ë. –ù–∞–ø—Ä–∏–º–µ—Ä: '
                    f'"—Ç—ã —Å–∫–∞–∑–∞–ª ¬´...¬ª ‚Äî –Ω—É —Ç—ã –¥–∞—ë—à—å" –∏–ª–∏ "¬´...¬ª ‚Äî —Å–µ—Ä—å—ë–∑–Ω–æ?!"'
                )

        if not messages or messages[0]["role"] != "system":
            messages = [{"role": "system", "content": system_prompt}] + messages

        logger.info(f"Grok request: model=grok-3-mini, messages={len(messages)}, system={messages[0]['content'][:80] if messages else 'none'}...")

        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=messages,
            ),
            timeout=60,
        )

        reply = (response.choices[0].message.content or "").strip()
        logger.info(f"GPT raw reply: {repr(reply)}, finish_reason={response.choices[0].finish_reason}")

        if not reply:
            return "—ç—ç—ç‚Ä¶ —è –∑–∞–¥—É–º–∞–ª–∞—Å—å üòÖ"

        if dumb_mode:
            words = reply.split()
            reply = " ".join(words[:MAX_WORDS])

        reply = lowercase_first(reply)
        return reply

    except Exception as e:
        logger.error(f"Grok API error: {e}", exc_info=True)
        return "—ç—ç—ç‚Ä¶ —è –∑–∞–≤–∏—Å–ª–∞ üò≥"
