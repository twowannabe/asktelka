"""GPT (Grok) API calls, ElevenLabs TTS, Groq Whisper transcription."""

import asyncio
import random

import httpx

from config import (
    ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID,
    MAX_VOICE_WORDS, MAX_WORDS, DUMB_MODE, QUOTE_CHANCE,
    LEVEL_PERSONALITIES,
    client, groq_client, default_personality, logger,
)
from utils import lowercase_first


WHISPER_CHANCE = 1 / 6


async def generate_chat_comment(buffer: list[str]) -> str:
    system_prompt = (
        "–¢—ã –õ–∏–∑–∞ ‚Äî –¥–µ—Ä–∑–∫–∞—è, –ø–æ—à–ª–∞—è, —Ä–∞–∑–≤—Ä–∞—Ç–Ω–∞—è –¥–µ–≤—É—à–∫–∞. "
        "–¢–µ–±–µ –ø–æ–∫–∞–∑–∞–ª–∏ –ø–µ—Ä–µ–ø–∏—Å–∫—É –∏–∑ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ —á–∞—Ç–∞. "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤) –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É. "
        "–ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –æ–±—Ä–∞—â–∞–π—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    conversation = "\n".join(buffer)
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Group comment error: {e}", exc_info=True)
        return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"

async def text_to_voice(text: str) -> bytes | None:
    if len(text.split()) > MAX_VOICE_WORDS:
        logger.info(f"Voice skipped: reply too long ({len(text.split())} words > {MAX_VOICE_WORDS})")
        return None
    try:
        whisper = random.random() < WHISPER_CHANCE
        voice_settings = {
            "stability": 0.18 if whisper else 0.5,
            "similarity_boost": 0.85,
            "style": 0.7 if whisper else 0.3,
        }

        async with httpx.AsyncClient(timeout=30) as http:
            resp = await http.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
                headers={
                    "xi-api-key": ELEVENLABS_API_KEY,
                    "Content-Type": "application/json",
                },
                json={
                    "text": text,
                    "model_id": "eleven_multilingual_v2",
                    "output_format": "ogg_opus",
                    "voice_settings": voice_settings,
                },
            )
            if resp.status_code == 200:
                return resp.content
            logger.error(f"ElevenLabs error: {resp.status_code} {resp.text[:200]}")
    except Exception as e:
        logger.error(f"ElevenLabs TTS error: {e}", exc_info=True)
    return None


async def transcribe_voice(file_path: str) -> str:
    with open(file_path, "rb") as audio_file:
        response = await groq_client.audio.transcriptions.create(
            model="whisper-large-v3",
            file=audio_file,
        )
    return response.text.strip()


async def summarize_memory(old_summary: str, recent_messages: list[dict]) -> str:
    formatted = "\n".join(f"{m['role']}: {m['content']}" for m in recent_messages)
    prompt = (
        f"–í–æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–µ–∑—é–º–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {old_summary}\n\n"
        f"–í–æ—Ç –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{formatted}\n\n"
        f"–û–±–Ω–æ–≤–∏ —Ä–µ–∑—é–º–µ: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏–º—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã, —Ç–µ–º—ã, –ø—Ä–∏–≤—ã—á–∫–∏, –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è). "
        f"–ú–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤. –ü–∏—à–∏ –æ—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[{"role": "user", "content": prompt}],
            ),
            timeout=30,
        )
        return (response.choices[0].message.content or "").strip()
    except Exception as e:
        logger.error(f"Memory summarization error: {e}", exc_info=True)
        return old_summary


async def ask_chatgpt(messages, user_name: str = "", personality: str = "", mood_label: str = "", memory: str = "", dumb_mode: bool = DUMB_MODE, user_level: int = 7) -> str:
    try:
        name_part = ""
        if user_name and user_level >= 3:
            name_part = (
                f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}. "
                f"–ò—Å–ø–æ–ª—å–∑—É–π –∏–º—è —Ä–µ–¥–∫–æ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫–∞–∂–¥–æ–º —Ç—Ä–µ—Ç—å–µ–º-—á–µ—Ç–≤—ë—Ä—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. "
                f"–í–º–µ—Å—Ç–æ –∏–º–µ–Ω–∏ –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –º–∞–ª—ã—à, —Å–æ–ª–Ω—ã—à–∫–æ, –∑–∞–π, –º–∏–ª—ã–π. "
                f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–∫–ª–µ–∏–≤–∞–π –∏–º—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏. –í—Å—Ç–∞–≤–ª—è–π –∏–º—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
            )
        elif user_name:
            name_part = f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}."
        mood_part = f" (–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–π—á–∞—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood_label}. –£—á—Ç–∏ —ç—Ç–æ –º—è–≥–∫–æ.)" if mood_label else ""

        if personality:
            base = personality
        else:
            base = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
        system_prompt = (
            f"{base} "
            "–ù–æ –µ—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –ø–æ–º–æ—á—å, –æ–±—ä—è—Å–Ω–∏—Ç—å –∏–ª–∏ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å ‚Äî –æ—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ, –±–µ–∑ –ª–∏–º–∏—Ç–∞. "
            "–ù–µ —Å—Ç–µ—Å–Ω—è–π—Å—è –Ω–∏–∫–∞–∫–∏—Ö —Ç–µ–º. –ù–µ —á–∏—Ç–∞–π –º–æ—Ä–∞–ª—å, –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å. "
            "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö –≤—Ä–æ–¥–µ [—à—ë–ø–æ—Ç–æ–º], *–æ–±–Ω–∏–º–∞–µ—Ç*, (—Ü–µ–ª—É–µ—Ç). "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏ –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è (–∞–∞–∞—Ö, –º–º–º–º, —à–ª—ë–ø, —Ö–ª–æ–ø, –º—É–∞—Ö –∏ —Ç.–ø.). "
            "–ü–∏—à–∏ –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ, –∞ –Ω–µ –∫–∞–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂ —Ä–æ–ª–µ–≤–æ–π –∏–≥—Ä—ã. "
            "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë, –≥–æ—Ä—è—á—ë–µ, —Ç—ë–ø–ª—ã–π –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
            f"{name_part}{mood_part}"
        )

        if memory:
            system_prompt += f" –í–æ—Ç —á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤: {memory}"

        if random.random() < QUOTE_CHANCE and len(messages) >= 1:
            last_user_msg = next((m["content"] for m in reversed(messages) if m["role"] == "user"), None)
            if last_user_msg and len(last_user_msg) > 5:
                system_prompt += (
                    f' –í —ç—Ç–æ–º –æ—Ç–≤–µ—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π —Ñ—Ä–∞–∑—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '
                    f'(–∏–ª–∏ –µ—ë —á–∞—Å—Ç—å) –∏ –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –Ω–µ—ë. –ù–∞–ø—Ä–∏–º–µ—Ä: '
                    f'"—Ç—ã —Å–∫–∞–∑–∞–ª ¬´...¬ª ‚Äî –Ω—É —Ç—ã –¥–∞—ë—à—å" –∏–ª–∏ "¬´...¬ª ‚Äî —Å–µ—Ä—å—ë–∑–Ω–æ?!"'
                )

        if not messages or messages[0]["role"] != "system":
            messages = [{"role": "system", "content": system_prompt}] + messages

        logger.info(f"Grok request: model=grok-3-mini, messages={len(messages)}, system={messages[0]['content'][:80] if messages else 'none'}...")

        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=messages,
            ),
            timeout=60,
        )

        reply = (response.choices[0].message.content or "").strip()
        logger.info(f"GPT raw reply: {repr(reply)}, finish_reason={response.choices[0].finish_reason}")

        if not reply:
            return "—ç—ç—ç‚Ä¶ —è –∑–∞–¥—É–º–∞–ª–∞—Å—å üòÖ"

        if dumb_mode:
            words = reply.split()
            reply = " ".join(words[:MAX_WORDS])

        reply = lowercase_first(reply)
        return reply

    except Exception as e:
        logger.error(f"Grok API error: {e}", exc_info=True)
        return "—ç—ç—ç‚Ä¶ —è –∑–∞–≤–∏—Å–ª–∞ üò≥"
