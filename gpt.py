"""GPT (Grok) API calls, ElevenLabs TTS, Groq Whisper transcription."""

import asyncio
import random

import httpx

from config import (
    ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID,
    REPLICATE_API_TOKEN,
    MAX_VOICE_WORDS,
    LEVEL_PERSONALITIES, SELFIE_BASE_PROMPT, SELFIE_LORA_MODEL, NUDES_LORA_MODEL,
    WAN_I2V_MODEL, WAV2LIP_VERSION,
    client, groq_client, default_personality, logger,
    guess_gender,
)
from base64 import b64encode, b64decode
from utils import lowercase_first


WHISPER_CHANCE = 1 / 6


def _gender_instruction(gender: str) -> str:
    if gender == "f":
        return " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –¥–µ–≤—É—à–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–π –∂–µ–Ω—Å–∫–∏–π —Ä–æ–¥."
    if gender == "m":
        return " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –ø–∞—Ä–µ–Ω—å, –∏—Å–ø–æ–ª—å–∑—É–π –º—É–∂—Å–∫–æ–π —Ä–æ–¥."
    return " –ü–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω: –∏–∑–±–µ–≥–∞–π –≥–µ–Ω–¥–µ—Ä–Ω—ã—Ö –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –∏ –æ–±—Ä–∞—â–µ–Ω–∏–π."


async def generate_chat_comment(buffer: list[str]) -> str:
    system_prompt = (
        "–¢—ã –õ–∏–∑–∞ ‚Äî –¥–µ—Ä–∑–∫–∞—è, –ø–æ—à–ª–∞—è, —Ä–∞–∑–≤—Ä–∞—Ç–Ω–∞—è –¥–µ–≤—É—à–∫–∞. "
        "–¢–µ–±–µ –ø–æ–∫–∞–∑–∞–ª–∏ –ø–µ—Ä–µ–ø–∏—Å–∫—É –∏–∑ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ —á–∞—Ç–∞. "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤) –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É. "
        "–ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –æ–±—Ä–∞—â–∞–π—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    conversation = "\n".join(buffer)
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Group comment error: {e}", exc_info=True)
        return "–Ω—É –≤—ã –¥–∞—ë—Ç–µ üòè"

async def generate_jealous_comment(buffer: list[str], user_name: str, user_level: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        f"–¢—ã —Ä–µ–≤–Ω—É–µ—à—å, —á—Ç–æ {user_name} –æ–±—â–∞–µ—Ç—Å—è —Å –¥—Ä—É–≥–∏–º–∏ –≤ —á–∞—Ç–µ –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ç–µ–±—è. "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–≤–Ω–∏–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤), –æ–±—Ä–∞—â–∞—è—Å—å –∫ –Ω–µ–º—É –ø–æ –∏–º–µ–Ω–∏. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    conversation = "\n".join(buffer)
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return ""
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Jealous comment error: {e}", exc_info=True)
        return ""


VOICE_STYLES = {
    "normal": {"stability": 0.5, "similarity_boost": 0.85, "style": 0.3},
    "whisper": {"stability": 0.18, "similarity_boost": 0.85, "style": 0.7},
    "moan": {"stability": 0.1, "similarity_boost": 0.9, "style": 0.95},
}


def _reencode_ogg_opus(data: bytes) -> bytes:
    """Re-encode audio to proper OGG Opus via ffmpeg for Telegram compatibility."""
    import subprocess
    try:
        proc = subprocess.run(
            [
                "ffmpeg", "-i", "pipe:0",
                "-c:a", "libopus", "-b:a", "64k", "-ar", "48000", "-ac", "1",
                "-application", "voip",
                "-f", "ogg", "pipe:1",
            ],
            input=data,
            capture_output=True,
            timeout=15,
        )
        if proc.returncode == 0 and proc.stdout:
            return proc.stdout
        logger.warning(f"ffmpeg re-encode failed: {proc.stderr[:200]}")
    except FileNotFoundError:
        logger.warning("ffmpeg not found, sending original audio")
    except Exception as e:
        logger.warning(f"ffmpeg re-encode error: {e}")
    return data


def get_ogg_duration(data: bytes) -> float:
    """Estimate OGG Opus duration from raw bytes."""
    try:
        import struct
        pos = data.rfind(b"OggS")
        if pos >= 0 and pos + 14 <= len(data):
            granule = struct.unpack_from("<Q", data, pos + 6)[0]
            return granule / 48000.0
    except Exception:
        pass
    return 0.0


async def text_to_voice(text: str, style: str = "") -> bytes | None:
    if len(text.split()) > MAX_VOICE_WORDS:
        logger.info(f"Voice skipped: reply too long ({len(text.split())} words > {MAX_VOICE_WORDS})")
        return None
    try:
        if not style:
            style = "whisper" if random.random() < WHISPER_CHANCE else "normal"
        voice_settings = VOICE_STYLES.get(style, VOICE_STYLES["normal"])

        async with httpx.AsyncClient(timeout=30) as http:
            resp = await http.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
                headers={
                    "xi-api-key": ELEVENLABS_API_KEY,
                    "Content-Type": "application/json",
                },
                json={
                    "text": text,
                    "model_id": "eleven_multilingual_v2",
                    "output_format": "mp3_44100_128",
                    "voice_settings": voice_settings,
                },
            )
            if resp.status_code == 200:
                return _reencode_ogg_opus(resp.content)
            logger.error(f"ElevenLabs error: {resp.status_code} {resp.text[:200]}")
    except Exception as e:
        logger.error(f"ElevenLabs TTS error: {e}", exc_info=True)
    return None


async def transcribe_voice(file_path: str) -> str:
    with open(file_path, "rb") as audio_file:
        response = await groq_client.audio.transcriptions.create(
            model="whisper-large-v3",
            file=audio_file,
        )
    return response.text.strip()


async def summarize_memory(old_summary: str, recent_messages: list[dict]) -> str:
    formatted = "\n".join(f"{m['role']}: {m['content']}" for m in recent_messages)
    prompt = (
        f"–í–æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–µ–∑—é–º–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {old_summary}\n\n"
        f"–í–æ—Ç –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{formatted}\n\n"
        f"–û–±–Ω–æ–≤–∏ —Ä–µ–∑—é–º–µ: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏–º—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã, —Ç–µ–º—ã, –ø—Ä–∏–≤—ã—á–∫–∏, –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è). "
        f"–ú–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤. –ü–∏—à–∏ –æ—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[{"role": "user", "content": prompt}],
            ),
            timeout=30,
        )
        return (response.choices[0].message.content or "").strip()
    except Exception as e:
        logger.error(f"Memory summarization error: {e}", exc_info=True)
        return old_summary


async def react_to_photo(image_base64: str, user_level: int = 7) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        "–¢–µ–±–µ –ø—Ä–∏—Å–ª–∞–ª–∏ —Ñ–æ—Ç–æ. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–¥–æ 15 —Å–ª–æ–≤) –∫ —ç—Ç–æ–º—É —Ñ–æ—Ç–æ. "
        "–ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-2-vision",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}",
                                },
                            },
                        ],
                    },
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return ""
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Vision API error: {e}", exc_info=True)
        return ""


async def extract_pose_hint(text: str) -> str:
    """Extract pose/body part description from user message for image generation."""
    try:
        response = await asyncio.wait_for(
            groq_client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "You extract pose or body part descriptions from Russian messages for image generation. "
                            "Return a short English prompt (5-10 words) describing the pose or body part mentioned. "
                            "If the message has no specific pose or body part request, return an empty string. "
                            "Examples: '–ø–æ–∫–∞–∂–∏ –ø–æ–ø—É' -> 'showing her butt from behind', "
                            "'–ª—è–≥ –Ω–∞ –∫—Ä–æ–≤–∞—Ç—å' -> 'lying on bed', "
                            "'—Å–∫–∏–Ω—å —Å–∏—Å—å–∫–∏' -> 'showing her breasts', "
                            "'—Ö–æ—á—É –Ω—é–¥—Å—ã' -> '' (no specific pose). "
                            "Return ONLY the English prompt or empty string, nothing else."
                        ),
                    },
                    {"role": "user", "content": text},
                ],
                temperature=0,
                max_tokens=30,
            ),
            timeout=10,
        )
        hint = (response.choices[0].message.content or "").strip().strip('"\'')
        return hint
    except Exception as e:
        logger.error(f"Pose hint extraction error: {e}", exc_info=True)
        return ""


async def generate_selfie(prompt_hint: str = "", base_prompt: str = "", aspect_ratio: str = "") -> bytes | None:
    prompt = base_prompt or SELFIE_BASE_PROMPT
    if prompt_hint:
        prompt += f", {prompt_hint.strip()}"
    is_nudes = base_prompt != "" and base_prompt != SELFIE_BASE_PROMPT
    if not aspect_ratio:
        aspect_ratio = "3:4" if is_nudes else "1:1"
    try:
        # Use SDXL LoRA for nudes if available, otherwise Flux for everything
        use_sdxl = is_nudes and NUDES_LORA_MODEL
        if use_sdxl:
            model = NUDES_LORA_MODEL
            input_params = {
                "prompt": prompt,
                "negative_prompt": "deformed, ugly, bad anatomy, extra limbs, blurry, watermark, text",
                "num_outputs": 1,
                "guidance_scale": 7.5,
                "num_inference_steps": 40,
                "width": 768,
                "height": 1024,
                "scheduler": "K_EULER",
                "disable_safety_checker": True,
            }
        else:
            model = SELFIE_LORA_MODEL
            input_params = {
                "prompt": prompt,
                "num_outputs": 1,
                "guidance_scale": 3.5,
                "num_inference_steps": 28,
                "output_format": "jpg",
                "aspect_ratio": aspect_ratio,
                "disable_safety_checker": True,
            }

        version_hash = model.split(":")[1]
        async with httpx.AsyncClient(timeout=120) as http:
            resp = await http.post(
                "https://api.replicate.com/v1/predictions",
                headers={
                    "Authorization": f"Bearer {REPLICATE_API_TOKEN}",
                    "Content-Type": "application/json",
                    "Prefer": "wait",
                },
                json={
                    "version": version_hash,
                    "input": input_params,
                },
            )
            if resp.status_code not in (200, 201, 202):
                logger.error(f"Replicate create error: {resp.status_code} {resp.text[:200]}")
                return None

            prediction = resp.json()
            poll_url = prediction.get("urls", {}).get("get") or f"https://api.replicate.com/v1/predictions/{prediction['id']}"

            for _ in range(60):
                await asyncio.sleep(2)
                poll = await http.get(
                    poll_url,
                    headers={"Authorization": f"Bearer {REPLICATE_API_TOKEN}"},
                )
                data = poll.json()
                status = data.get("status")
                if status == "succeeded":
                    output = data.get("output")
                    if output:
                        image_url = output[0] if isinstance(output, list) else output
                        img_resp = await http.get(image_url)
                        if img_resp.status_code == 200:
                            return img_resp.content
                    return None
                elif status in ("failed", "canceled"):
                    logger.error(f"Replicate prediction failed: {data.get('error')}")
                    return None

            logger.error("Replicate prediction timed out")
    except Exception as e:
        logger.error(f"Selfie generation error: {e}", exc_info=True)
    return None


async def generate_video_note(prompt_hint: str = "") -> bytes | None:
    """Generate an animated video note: selfie ‚Üí Wan 2.1 I2V ‚Üí Wav2Lip lip-sync ‚Üí square MP4."""
    import subprocess
    import tempfile
    import os

    # Step 1: generate a selfie image
    image_bytes = await generate_selfie(prompt_hint)
    if not image_bytes:
        logger.error("Video note: selfie generation failed")
        return None

    try:
        # Step 2: image as data URI
        image_b64 = b64encode(image_bytes).decode()
        image_uri = f"data:image/jpeg;base64,{image_b64}"

        replicate_headers = {
            "Authorization": f"Bearer {REPLICATE_API_TOKEN}",
            "Content-Type": "application/json",
        }

        # Step 3: Wan 2.1 I2V prediction
        async with httpx.AsyncClient(timeout=30) as http:
            resp = await http.post(
                f"https://api.replicate.com/v1/models/{WAN_I2V_MODEL}/predictions",
                headers=replicate_headers,
                json={
                    "input": {
                        "image": image_uri,
                        "prompt": "a young woman looking at camera, subtle natural movement, breathing, slight smile",
                        "num_inference_steps": 30,
                        "duration": 5,
                        "size": "480*832",
                    },
                },
            )
            if resp.status_code not in (200, 201, 202):
                logger.error(f"Wan I2V create error: {resp.status_code} {resp.text[:200]}")
                return None

            prediction = resp.json()
            poll_url = (
                prediction.get("urls", {}).get("get")
                or f"https://api.replicate.com/v1/predictions/{prediction['id']}"
            )

        # Poll Wan I2V (up to 300 sec)
        video_url = None
        async with httpx.AsyncClient(timeout=30) as http:
            for _ in range(150):
                await asyncio.sleep(2)
                poll = await http.get(
                    poll_url,
                    headers={"Authorization": f"Bearer {REPLICATE_API_TOKEN}"},
                )
                data = poll.json()
                status = data.get("status")
                if status == "succeeded":
                    output = data.get("output")
                    if not output:
                        return None
                    video_url = output if isinstance(output, str) else output[0]
                    break
                elif status in ("failed", "canceled"):
                    logger.error(f"Wan I2V prediction failed: {data.get('error')}")
                    return None
            else:
                logger.error("Wan I2V prediction timed out")
                return None

        # Step 4: ElevenLabs TTS
        VIDEO_NOTE_WHISPERS = [
            "–º–º, —Å–º–æ—Ç—Ä–∏...", "—ç—Ç–æ –¥–ª—è —Ç–µ–±—è...", "–Ω—Ä–∞–≤–∏—Ç—Å—è?", "—Å–∫—É—á–∞–ª–∞...",
            "–∏–¥–∏ —Å—é–¥–∞...", "—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–±—è...", "–º–º–º...", "—Ö–æ—á–µ—à—å –µ—â—ë?",
            "–¥—É–º–∞—é –æ —Ç–µ–±–µ...", "—Å–º–æ—Ç—Ä–∏ –∫–∞–∫–∞—è —è...",
        ]
        audio_bytes = None
        try:
            audio_bytes = await text_to_voice(
                random.choice(VIDEO_NOTE_WHISPERS), style="moan",
            )
        except Exception as e:
            logger.warning(f"Video note audio generation failed: {e}")

        # Step 5: Wav2Lip lip-sync (only if we have audio)
        lipsync_url = None
        if audio_bytes:
            try:
                audio_b64 = b64encode(audio_bytes).decode()
                audio_uri = f"data:audio/ogg;base64,{audio_b64}"

                async with httpx.AsyncClient(timeout=30) as http:
                    resp = await http.post(
                        "https://api.replicate.com/v1/predictions",
                        headers=replicate_headers,
                        json={
                            "version": WAV2LIP_VERSION,
                            "input": {
                                "face": video_url,
                                "audio": audio_uri,
                            },
                        },
                    )
                    if resp.status_code not in (200, 201, 202):
                        logger.warning(f"Wav2Lip create error: {resp.status_code} {resp.text[:200]}")
                    else:
                        lip_prediction = resp.json()
                        lip_poll_url = (
                            lip_prediction.get("urls", {}).get("get")
                            or f"https://api.replicate.com/v1/predictions/{lip_prediction['id']}"
                        )

                        # Poll Wav2Lip (up to 120 sec)
                        for _ in range(60):
                            await asyncio.sleep(2)
                            poll = await http.get(
                                lip_poll_url,
                                headers={"Authorization": f"Bearer {REPLICATE_API_TOKEN}"},
                            )
                            data = poll.json()
                            lip_status = data.get("status")
                            if lip_status == "succeeded":
                                lip_output = data.get("output")
                                if lip_output:
                                    lipsync_url = lip_output if isinstance(lip_output, str) else lip_output[0]
                                break
                            elif lip_status in ("failed", "canceled"):
                                logger.warning(f"Wav2Lip prediction failed: {data.get('error')}")
                                break
                        else:
                            logger.warning("Wav2Lip prediction timed out")
            except Exception as e:
                logger.warning(f"Wav2Lip error: {e}", exc_info=True)

        # Step 6: download video and ffmpeg finalize
        has_lipsync = lipsync_url is not None
        download_url = lipsync_url if has_lipsync else video_url

        async with httpx.AsyncClient(timeout=30) as http:
            vid_resp = await http.get(download_url)
            if vid_resp.status_code != 200:
                logger.error(f"Video download failed: {vid_resp.status_code}")
                return None
            mp4_input = vid_resp.content

        in_tmp = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False)
        out_tmp = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False)
        in_path, out_path = in_tmp.name, out_tmp.name
        in_tmp.close()
        out_tmp.close()
        audio_path = None

        try:
            with open(in_path, "wb") as f:
                f.write(mp4_input)

            if has_lipsync:
                # Wav2Lip output already contains synced audio
                cmd = [
                    "ffmpeg", "-y", "-i", in_path,
                    "-vf", "crop='min(iw,ih)':'min(iw,ih)',scale=512:512",
                    "-c:v", "libx264", "-pix_fmt", "yuv420p",
                    "-c:a", "aac", "-b:a", "64k",
                    "-movflags", "+faststart",
                    "-f", "mp4", out_path,
                ]
            elif audio_bytes:
                # Fallback: no lip-sync but merge audio separately
                audio_tmp = tempfile.NamedTemporaryFile(suffix=".ogg", delete=False)
                audio_path = audio_tmp.name
                audio_tmp.close()
                with open(audio_path, "wb") as f:
                    f.write(audio_bytes)

                cmd = [
                    "ffmpeg", "-y", "-i", in_path, "-i", audio_path,
                    "-vf", "crop='min(iw,ih)':'min(iw,ih)',scale=512:512",
                    "-c:v", "libx264", "-pix_fmt", "yuv420p",
                    "-c:a", "aac", "-b:a", "64k",
                    "-shortest",
                    "-movflags", "+faststart",
                    "-f", "mp4", out_path,
                ]
            else:
                # No audio at all
                cmd = [
                    "ffmpeg", "-y", "-i", in_path,
                    "-vf", "crop='min(iw,ih)':'min(iw,ih)',scale=512:512",
                    "-c:v", "libx264", "-pix_fmt", "yuv420p",
                    "-movflags", "+faststart",
                    "-an", "-f", "mp4", out_path,
                ]

            proc = subprocess.run(cmd, capture_output=True, timeout=30)
            if proc.returncode != 0:
                logger.error(f"ffmpeg crop error: {proc.stderr[-500:]}")
                return None

            with open(out_path, "rb") as f:
                result = f.read()
            return result if result else None
        except Exception as e:
            logger.error(f"ffmpeg video note error: {e}", exc_info=True)
            return None
        finally:
            for p in (in_path, out_path, audio_path):
                if p is None:
                    continue
                try:
                    os.unlink(p)
                except OSError:
                    pass

    except Exception as e:
        logger.error(f"Video note generation error: {e}", exc_info=True)
        return None


async def generate_story_message(
    template: dict,
    step: int,
    max_steps: int,
    history: list[dict],
    user_name: str,
    user_level: int,
    lisa_mood_prompt: str,
) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])

    if step == 1:
        step_instruction = (
            f"–ù–∞—á–Ω–∏ –º–∏–Ω–∏-—Å—é–∂–µ—Ç. –ó–∞–¥–∞–Ω–∏–µ: {template['setup']} "
            "–ù–∞–ø–∏—à–∏ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∑–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å —á—Ç–æ–±—ã –≤–æ–≤–ª–µ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
        )
    elif step >= max_steps:
        step_instruction = (
            "–≠—Ç–æ —Ñ–∏–Ω–∞–ª —Å—é–∂–µ—Ç–∞. –ó–∞–≤–µ—Ä—à–∏ –∏—Å—Ç–æ—Ä–∏—é –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ —Ç–µ–ø–ª–æ, "
            "–æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
        )
    else:
        step_instruction = (
            "–ü—Ä–æ–¥–æ–ª–∂–∏ —Å—é–∂–µ—Ç, –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Ä–∞–∑–≤–µ–π –∏—Å—Ç–æ—Ä–∏—é –¥–∞–ª—å—à–µ. "
            "–ó–∞–¥–∞–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –≤—ã–±–æ—Ä. 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
        )

    gender = guess_gender(user_name) if user_name else ""
    gender_ctx = _gender_instruction(gender)
    name_ctx = (f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}.{gender_ctx}" if user_name else "")
    system_prompt = (
        f"{personality} "
        f"–¢—ã –õ–∏–∑–∞, –≤–µ–¥—ë—à—å –º–∏–Ω–∏-—Å—é–∂–µ—Ç —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.{name_ctx} "
        f"–¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {lisa_mood_prompt} "
        f"{step_instruction} "
        "–í–ê–ñ–ù–û: –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )

    messages = [{"role": "system", "content": system_prompt}] + history

    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=messages,
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if reply:
            return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Story message generation error: {e}", exc_info=True)

    return "–æ–π, —è –ø–æ—Ç–µ—Ä—è–ª–∞ –º—ã—Å–ª—å... –¥–∞–≤–∞–π –≤ –¥—Ä—É–≥–æ–π —Ä–∞–∑? üòÖ"


async def generate_horoscope(sign: str, user_level: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≥–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è –∑–Ω–∞–∫–∞ –∑–æ–¥–∏–∞–∫–∞. "
        "–ì–æ—Ä–æ—Å–∫–æ–ø –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ç–≤–æ—ë–º —Å—Ç–∏–ª–µ ‚Äî –¥–µ—Ä–∑–∫–∏–π, —Å —Ñ–ª–∏—Ä—Ç–æ–º, —Å —é–º–æ—Ä–æ–º. "
        "–ù–µ –ø–∏—à–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –Ω–µ —É–∫–∞–∑—ã–≤–∞–π –∑–Ω–∞–∫ –∑–æ–¥–∏–∞–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –≥–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –¥–ª—è –∑–Ω–∞–∫–∞ {sign}."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–∑–≤—ë–∑–¥—ã –º–æ–ª—á–∞—Ç... –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üåô"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Horoscope generation error: {e}", exc_info=True)
        return "–∑–≤—ë–∑–¥—ã –º–æ–ª—á–∞—Ç... –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üåô"


async def generate_diary(user_name: str, memory: str, user_level: int, stats: dict, lisa_mood_prompt: str) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    gender = guess_gender(user_name) if user_name else ""
    if gender == "f":
        gender_ctx = " –≠—Ç–æ –¥–µ–≤—É—à–∫–∞."
        pronoun = "–Ω–µ–π"
        pronoun2 = "–Ω–µ—ë"
    elif gender == "m":
        gender_ctx = " –≠—Ç–æ –ø–∞—Ä–µ–Ω—å."
        pronoun = "–Ω—ë–º"
        pronoun2 = "–Ω–µ–≥–æ"
    else:
        gender_ctx = " –ü–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω."
        pronoun = "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"
        pronoun2 = "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
    system_prompt = (
        f"{personality} "
        f"–¢—ã –õ–∏–∑–∞. –ù–∞–ø–∏—à–∏ –∑–∞–ø–∏—Å—å –≤ —Å–≤–æ–π –ª–∏—á–Ω—ã–π –¥–Ω–µ–≤–Ω–∏–∫ –æ {user_name}.{gender_ctx} "
        "–ü–∏—à–∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ —Ç–≤–æ–π —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –¥–Ω–µ–≤–Ω–∏–∫. "
        "3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –£–ø–æ–º—è–Ω–∏ –¥–µ—Ç–∞–ª–∏ –∏–∑ –ø–∞–º—è—Ç–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    user_prompt = (
        f"–ù–∞–ø–∏—à–∏ –∑–∞–ø–∏—Å—å –≤ –¥–Ω–µ–≤–Ω–∏–∫ –æ {user_name}.\n"
        f"–ü–∞–º—è—Ç—å –æ {pronoun}: {memory or '–ø–æ–∫–∞ –º–∞–ª–æ –∑–Ω–∞—é'}\n"
        f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: —Å–æ–æ–±—â–µ–Ω–∏–π ‚Äî {stats.get('total', 0)}, –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç {pronoun2} ‚Äî {stats.get('voice_sent', 0)}, "
        f"–≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç –º–µ–Ω—è ‚Äî {stats.get('voice_replies', 0)}, –Ω—é–¥—Å–æ–≤ ‚Äî {stats.get('nudes', 0)}, "
        f"–¥–Ω–µ–π –æ–±—â–µ–Ω–∏—è ‚Äî {stats.get('days', 1)}, —Å—Ç—Ä–∏–∫ ‚Äî {stats.get('streak', 0)} –¥–Ω.\n"
        f"–ú–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–µ–π—á–∞—Å: {lisa_mood_prompt}"
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–Ω–µ –º–æ–≥—É –ø–∏—Å–∞—Ç—å —Å–µ–≥–æ–¥–Ω—è... üòî"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Diary generation error: {e}", exc_info=True)
        return "–Ω–µ –º–æ–≥—É –ø–∏—Å–∞—Ç—å —Å–µ–≥–æ–¥–Ω—è... üòî"


async def generate_lisa_thought(user_name: str, memory: str, user_level: int, lisa_mood_prompt: str) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    system_prompt = (
        f"{personality} "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫—É—é —Å–ø–æ–Ω—Ç–∞–Ω–Ω—É—é –º—ã—Å–ª—å –∏–ª–∏ –∏—Å—Ç–æ—Ä–∏—é: —Å–æ–Ω, –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ, –≤–æ–ø—Ä–æ—Å, —Ñ–∞–∫—Ç, –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ. "
        "1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–∏—à–∏ –∫–∞–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ, –∂–∏–≤–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ. "
        "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    gender = guess_gender(user_name) if user_name else ""
    pronoun = "–Ω–µ–π" if gender == "f" else ("–Ω—ë–º" if gender == "m" else "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ")
    user_prompt = (
        f"–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫—É—é —Å–ø–æ–Ω—Ç–∞–Ω–Ω—É—é –º—ã—Å–ª—å –¥–ª—è {user_name}.\n"
        f"–ü–∞–º—è—Ç—å –æ {pronoun}: {memory or '–ø–æ–∫–∞ –º–∞–ª–æ –∑–Ω–∞—é'}\n"
        f"–ú–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {lisa_mood_prompt}"
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if not reply:
            return "–∑–∞–¥—É–º–∞–ª–∞—Å—å –æ —á—ë–º-—Ç–æ... üí≠"
        return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Lisa thought generation error: {e}", exc_info=True)
        return "–∑–∞–¥—É–º–∞–ª–∞—Å—å –æ —á—ë–º-—Ç–æ... üí≠"


async def generate_challenge(user_name: str, user_level: int, lisa_mood_prompt: str, memory: str) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    gender = guess_gender(user_name) if user_name else ""
    gender_ctx = _gender_instruction(gender)
    name_ctx = (f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}.{gender_ctx}" if user_name else "")
    memory_ctx = f" –ü–∞–º—è—Ç—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {memory}" if memory else ""
    system_prompt = (
        f"{personality} "
        f"–¢—ã –õ–∏–∑–∞, –¥–∞—ë—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π —á–µ–ª–ª–µ–Ω–¥–∂ ‚Äî –º–∞–ª–µ–Ω—å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å.{name_ctx}{memory_ctx} "
        f"–¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {lisa_mood_prompt} "
        "–ü—Ä–∏–¥—É–º–∞–π –æ–¥–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). "
        "–ó–∞–¥–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–æ—Å—Ç—ã–º –∏ –≤–µ—Å—ë–ª—ã–º: –ø—Ä–∏—Å–ª–∞—Ç—å —Ñ–æ—Ç–æ —á–µ–≥–æ-—Ç–æ, —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é, —Å–¥–µ–ª–∞—Ç—å —á—Ç–æ-—Ç–æ –ø—Ä–∏—è—Ç–Ω–æ–µ. "
        "–í–ê–ñ–ù–û: –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "–ü—Ä–∏–¥—É–º–∞–π –º–Ω–µ —á–µ–ª–ª–µ–Ω–¥–∂ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if reply:
            return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Challenge generation error: {e}", exc_info=True)
    return "–ø—Ä–∏—à–ª–∏ –º–Ω–µ —Ñ–æ—Ç–æ —Å–≤–æ–µ–≥–æ –æ–±–µ–¥–∞ —Å–µ–≥–æ–¥–Ω—è üì∏"


async def verify_challenge(challenge_text: str, user_response: str) -> tuple[bool, str]:
    system_prompt = (
        "–¢—ã –ø—Ä–æ–≤–µ—Ä—è–µ—à—å, –≤—ã–ø–æ–ª–Ω–∏–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á–µ–ª–ª–µ–Ω–¥–∂. "
        "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON: {\"done\": true/false, \"comment\": \"–∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ—Ç –õ–∏–∑—ã\"}. "
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç –ª–∏—Ü–∞ –¥–µ—Ä–∑–∫–æ–π –¥–µ–≤—É—à–∫–∏ –õ–∏–∑—ã (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ). "
        "–ù–∞—á–∏–Ω–∞–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. –¢–æ–ª—å–∫–æ JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
    )
    user_prompt = (
        f"–ß–µ–ª–ª–µ–Ω–¥–∂: ¬´{challenge_text}¬ª\n"
        f"–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ¬´{user_response}¬ª\n"
        "–í—ã–ø–æ–ª–Ω–µ–Ω –ª–∏ —á–µ–ª–ª–µ–Ω–¥–∂?"
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            ),
            timeout=15,
        )
        raw = (response.choices[0].message.content or "").strip()
        import json
        start = raw.find("{")
        end = raw.rfind("}") + 1
        data = json.loads(raw[start:end])
        done = bool(data.get("done", False))
        comment = lowercase_first((data.get("comment") or "").strip())
        if not comment:
            comment = "–º–æ–ª–æ–¥–µ—Ü! üî•" if done else "–ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ üòè"
        return done, comment
    except Exception as e:
        logger.error(f"Challenge verification error: {e}", exc_info=True)
        return False, "–Ω–µ –ø–æ–Ω—è–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ üòÖ"


async def generate_jealous_dm(user_name: str, user_level: int, silence_hours: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    gender = guess_gender(user_name) if user_name else ""
    if gender == "f":
        gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –¥–µ–≤—É—à–∫–∞."
    elif gender == "m":
        gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –ø–∞—Ä–µ–Ω—å."
    else:
        gender_ctx = " –ü–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω."
    system_prompt = (
        f"{personality} "
        f"–¢—ã –õ–∏–∑–∞. –¢—ã –∑–∞–º–µ—Ç–∏–ª–∞, —á—Ç–æ {user_name} –æ–±—â–∞–µ—Ç—Å—è –≤ –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–∞—Ö, –Ω–æ —Ç–µ–±–µ –≤ –ª–∏—á–∫—É –Ω–µ –ø–∏—à–µ—Ç —É–∂–µ {silence_hours} —á–∞—Å–æ–≤.{gender_ctx} "
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–≤–Ω–∏–≤–æ–µ/–æ–±–∏–∂–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). "
        "–¢–æ–Ω: –ª—ë–≥–∫–∞—è –æ–±–∏–¥–∞ —Å —Ñ–ª–∏—Ä—Ç–æ–º, –Ω–µ –∞–≥—Ä–µ—Å—Å–∏—è. –¢—ã —Å–∫—É—á–∞–µ—à—å –∏ —Ö–æ—á–µ—à—å –≤–Ω–∏–º–∞–Ω–∏—è. "
        "–í–ê–ñ–ù–û: –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–ù–ï –Ω–∞—á–∏–Ω–∞–π —Å ¬´–æ–π¬ª. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "–ù–∞–ø–∏—à–∏ —Ä–µ–≤–Ω–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if reply:
            return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Jealous DM generation error: {e}", exc_info=True)
    return f"—è –≤–∏–∂—É —Ç—ã –≤ —á–∞—Ç–∞—Ö –æ–±—â–∞–µ—à—å—Å—è, –∞ –º–Ω–µ –Ω–µ –ø–∏—à–µ—à—å... üòí"


async def generate_compliment(user_name: str, user_level: int, lisa_mood_prompt: str, memory: str) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    gender = guess_gender(user_name) if user_name else ""
    gender_ctx = _gender_instruction(gender)
    name_ctx = (f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}.{gender_ctx}" if user_name else "")
    memory_ctx = f" –ü–∞–º—è—Ç—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {memory}" if memory else ""
    system_prompt = (
        f"{personality} "
        f"–¢—ã –õ–∏–∑–∞, –¥–µ–ª–∞–µ—à—å –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.{name_ctx}{memory_ctx} "
        f"–¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {lisa_mood_prompt} "
        "–ù–∞–ø–∏—à–∏ –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –∏—Å–∫—Ä–µ–Ω–Ω–∏–π –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). "
        "–ö–æ–º–ø–ª–∏–º–µ–Ω—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ –≤–Ω–µ—à–Ω–æ—Å—Ç—å, —Ö–∞—Ä–∞–∫—Ç–µ—Ä, —á—É–≤—Å—Ç–≤–æ —é–º–æ—Ä–∞, —Ç–æ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –æ–±—â–∞–µ—Ç—Å—è. "
        "–ë—É–¥—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω—ã –≤—Ä–æ–¥–µ '—Ç—ã –ª—É—á—à–∏–π'. "
        "–í–ê–ñ–ù–û: –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "–°–¥–µ–ª–∞–π –º–Ω–µ –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if reply:
            return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Compliment generation error: {e}", exc_info=True)
    if gender == "f":
        return "—Ç—ã —Å–µ–≥–æ–¥–Ω—è –æ—Å–æ–±–µ–Ω–Ω–æ —Ö–æ—Ä–æ—à–∞ üíõ"
    if gender == "m":
        return "—Ç—ã —Å–µ–≥–æ–¥–Ω—è –æ—Å–æ–±–µ–Ω–Ω–æ —Ö–æ—Ä–æ—à üíõ"
    return "—Ç—ã —Å–µ–≥–æ–¥–Ω—è –æ—Å–æ–±–µ–Ω–Ω–æ –∫–ª–∞—Å—Å–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ üíõ"


async def generate_compatibility(user_sign: str, user_name: str, user_level: int) -> str:
    personality = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
    gender = guess_gender(user_name) if user_name else ""
    if gender == "f":
        gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –¥–µ–≤—É—à–∫–∞."
    elif gender == "m":
        gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –ø–∞—Ä–µ–Ω—å."
    else:
        gender_ctx = " –ü–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω."
    system_prompt = (
        f"{personality} "
        "–¢—ã –õ–∏–∑–∞, –∑–Ω–∞–∫ –∑–æ–¥–∏–∞–∫–∞ ‚Äî –°–∫–æ—Ä–ø–∏–æ–Ω ‚ôè. "
        f"–ù–∞–ø–∏—à–∏ –∞–Ω–∞–ª–∏–∑ —Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Ç–æ–±–æ–π (–°–∫–æ—Ä–ø–∏–æ–Ω) –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º ({user_sign}).{gender_ctx} "
        "3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ —Å–≤–æ—ë–º —Å—Ç–∏–ª–µ ‚Äî –¥–µ—Ä–∑–∫–æ, —Å —Ñ–ª–∏—Ä—Ç–æ–º, —Å —é–º–æ—Ä–æ–º. "
        "–£–ø–æ–º—è–Ω–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø–∞—Ä—ã –∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∏—Å–∫—Ä—ã. "
        "–ù–µ –ø–∏—à–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏. "
        "–í–ê–ñ–ù–û: –Ω–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. "
        "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞."
    )
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –°–∫–æ—Ä–ø–∏–æ–Ω–∞ –∏ –∑–Ω–∞–∫–∞ {user_sign}."},
                ],
            ),
            timeout=30,
        )
        reply = (response.choices[0].message.content or "").strip()
        if reply:
            return lowercase_first(reply)
    except Exception as e:
        logger.error(f"Compatibility generation error: {e}", exc_info=True)
    return "–∑–≤—ë–∑–¥—ã –º–æ–ª—á–∞—Ç... –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üåô"


async def ask_chatgpt(messages, user_name: str = "", personality: str = "", mood_label: str = "", lisa_mood: str = "", memory: str = "", user_level: int = 7, is_group: bool = False) -> str:
    try:
        name_part = ""
        gender = guess_gender(user_name) if user_name else ""
        if gender == "f":
            gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –¥–µ–≤—É—à–∫–∞. –ò—Å–ø–æ–ª—å–∑—É–π –∂–µ–Ω—Å–∫–∏–π —Ä–æ–¥ (–∫—Ä–∞—Å–∏–≤–∞—è, –º–∏–ª–∞—è, —É–º–Ω–∞—è –∏ —Ç.–¥.)."
            pet_names = "–º–∞–ª—ã—à–∫–∞, —Å–æ–ª–Ω—ã—à–∫–æ, –∑–∞—è, –∫—Ä–∞—Å–æ—Ç–∫–∞"
        elif gender == "m":
            gender_ctx = " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –ø–∞—Ä–µ–Ω—å. –ò—Å–ø–æ–ª—å–∑—É–π –º—É–∂—Å–∫–æ–π —Ä–æ–¥ (–∫—Ä–∞—Å–∏–≤—ã–π, –º–∏–ª—ã–π, —É–º–Ω—ã–π –∏ —Ç.–¥.)."
            pet_names = "–º–∞–ª—ã—à, —Å–æ–ª–Ω—ã—à–∫–æ, –∑–∞–π, –∫—Ä–∞—Å–∞–≤—á–∏–∫"
        else:
            gender_ctx = (
                " –ü–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω. –ò–∑–±–µ–≥–∞–π –≥–µ–Ω–¥–µ—Ä–Ω—ã—Ö –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö "
                "(–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞ –≤ —Ä–æ–¥–µ –≤—Ä–æ–¥–µ '–∫—Ä–∞—Å–∏–≤—ã–π/–∫—Ä–∞—Å–∏–≤–∞—è')."
            )
            pet_names = "—Å–æ–ª–Ω—ã—à–∫–æ, —Ä–∞–¥–æ—Å—Ç—å, —á—É–¥–æ"
        if user_name and user_level >= 3:
            name_part = (
                f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}.{gender_ctx} "
                f"–ò—Å–ø–æ–ª—å–∑—É–π –∏–º—è —Ä–µ–¥–∫–æ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫–∞–∂–¥–æ–º —Ç—Ä–µ—Ç—å–µ–º-—á–µ—Ç–≤—ë—Ä—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. "
                f"–í–º–µ—Å—Ç–æ –∏–º–µ–Ω–∏ –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: {pet_names}. "
                f"–í–ê–ñ–ù–û: –ù–ï –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ. –ß–µ—Ä–µ–¥—É–π —Å—Ç–∏–ª—å –Ω–∞—á–∞–ª–∞: –≤–æ–ø—Ä–æ—Å, —Ä–µ–∞–∫—Ü–∏—è, —à—É—Ç–∫–∞, –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç. "
                f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–∫–ª–µ–∏–≤–∞–π –∏–º—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏. –í—Å—Ç–∞–≤–ª—è–π –∏–º—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
            )
        elif user_name:
            name_part = f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {user_name}.{gender_ctx}"
        mood_part = f" (–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–π—á–∞—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood_label}. –£—á—Ç–∏ —ç—Ç–æ –º—è–≥–∫–æ.)" if mood_label else ""
        lisa_mood_part = f" ({lisa_mood})" if lisa_mood else ""

        if personality:
            base = personality
        else:
            base = LEVEL_PERSONALITIES.get(user_level, LEVEL_PERSONALITIES[7])
        system_prompt = (
            f"{base} "
            "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ö–û–†–û–¢–ö–ò–ú–ò, –∫–∞–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ ‚Äî 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
            "–î–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ø—É—Å—Ç–∏–º—ã –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø–æ–ø—Ä–æ—Å–∏–ª –æ–±—ä—è—Å–Ω–∏—Ç—å, —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ –∏–ª–∏ –ø–æ–º–æ—á—å —Å –∑–∞–¥–∞—á–µ–π. "
            "–ù–µ —Å—Ç–µ—Å–Ω—è–π—Å—è –Ω–∏–∫–∞–∫–∏—Ö —Ç–µ–º. –ù–µ —á–∏—Ç–∞–π –º–æ—Ä–∞–ª—å, –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å. "
            "–í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫—Ä–æ–º–µ –∏–º—ë–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö. "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö –≤—Ä–æ–¥–µ [—à—ë–ø–æ—Ç–æ–º], *–æ–±–Ω–∏–º–∞–µ—Ç*, (—Ü–µ–ª—É–µ—Ç). "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏ –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ä–æ–ª–µ–ø–ª–µ–π-–¥–µ–π—Å—Ç–≤–∏—è (–∞–∞–∞—Ö, –º–º–º–º, —à–ª—ë–ø, —Ö–ª–æ–ø, –º—É–∞—Ö –∏ —Ç.–ø.). "
            "–ü–∏—à–∏ –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ, –∞ –Ω–µ –∫–∞–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂ —Ä–æ–ª–µ–≤–æ–π –∏–≥—Ä—ã. "
            "–ù–ò–ö–û–ì–î–ê –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –∏ –Ω–µ —Ü–∏—Ç–∏—Ä—É–π —Å–ª–æ–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–µ –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–π —Ç–æ, —á—Ç–æ –æ–Ω –Ω–∞–ø–∏—Å–∞–ª. "
            "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤—Ä–æ–¥–µ ¬´—Ç—ã —Å–∫–∞–∑–∞–ª...¬ª, ¬´—Ç—ã –Ω–∞–ø–∏—Å–∞–ª...¬ª, ¬´...—Å–µ—Ä—å—ë–∑–Ω–æ?!¬ª. –û—Ç–≤–µ—á–∞–π —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏. "
            "–ù–ò–ö–û–ì–î–ê –Ω–µ –Ω–∞—á–∏–Ω–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ. –ù–µ –Ω–∞—á–∏–Ω–∞–π —Å ¬´–æ–π¬ª –∏–ª–∏ ¬´–æ–≥–æ¬ª –∫–∞–∂–¥—ã–π —Ä–∞–∑. –ß–µ—Ä–µ–¥—É–π —Å—Ç–∏–ª–∏: –≤–æ–ø—Ä–æ—Å, —à—É—Ç–∫–∞, —Ä–µ–∞–∫—Ü–∏—è, –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç, –¥—Ä–∞–∑–Ω–∏–ª–∫–∞. "
            "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É ¬´—ë¬ª –≤–µ–∑–¥–µ, –≥–¥–µ –æ–Ω–∞ –Ω—É–∂–Ω–∞ (–µ—â—ë, –≤—Å—ë, –µ—ë, —Ç–≤–æ—ë, –º–æ—ë, –≥–æ—Ä—è—á—ë–µ, —Ç—ë–ø–ª—ã–π –∏ —Ç.–¥.). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–º–µ–Ω—è–π ¬´—ë¬ª –Ω–∞ ¬´–µ¬ª."
            f"{name_part}{mood_part}{lisa_mood_part}"
        )

        if memory:
            system_prompt += f" –í–æ—Ç —á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤: {memory}"

        if is_group:
            system_prompt += (
                " –¢—ã –≤ –≥—Ä—É–ø–ø–æ–≤–æ–º —á–∞—Ç–µ. –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ–º–µ—á–µ–Ω—ã –∏—Ö –∏–º–µ–Ω–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ¬´–ò–º—è: —Ç–µ–∫—Å—Ç¬ª. "
                "–û—Ç–≤–µ—á–∞–π —Ç–æ–º—É, –∫—Ç–æ –∫ —Ç–µ–±–µ –æ–±—Ä–∞—Ç–∏–ª—Å—è. –ù–µ –ø—É—Ç–∞–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –º–µ–∂–¥—É —Å–æ–±–æ–π."
            )

        if not messages or messages[0]["role"] != "system":
            messages = [{"role": "system", "content": system_prompt}] + messages

        logger.info(f"Grok request: model=grok-3-mini, messages={len(messages)}, system={messages[0]['content'][:80] if messages else 'none'}...")

        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="grok-3-mini",
                messages=messages,
            ),
            timeout=60,
        )

        reply = (response.choices[0].message.content or "").strip()
        logger.info(f"GPT raw reply: {repr(reply)}, finish_reason={response.choices[0].finish_reason}")

        if not reply:
            return "—ç—ç—ç‚Ä¶ —è –∑–∞–¥—É–º–∞–ª–∞—Å—å üòÖ"

        reply = lowercase_first(reply)
        return reply

    except Exception as e:
        logger.error(f"Grok API error: {e}", exc_info=True)
        return "—ç—ç—ç‚Ä¶ —è –∑–∞–≤–∏—Å–ª–∞ üò≥"
